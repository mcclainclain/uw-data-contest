for (i in 1:length(L)) {
new_list = c(new_list, str_trim(str_split_1(L[i], "/")[1]))
}
return (new_list)
}
# Scraping
BASE_URL = "https://mutigers.com"
years = 2023:2023 # List of years that we want to look at. Normally this would be something like 2013:2023.
college_df = data.frame() # Initializing an empty dataframe that we can add to.
for (i in 1:nrow(sports_df)) {
sport = sports_df$Sport[i] # Easier for readability
for (y in 1:length(years)) {
year = years[y] # Easier for readability
# If the sport's url is presented as 2023-24 (type 1), we want to convert the year in our for loop to be of that format.
if (sports_df$Type[i] == 1) {
next_year = as.character(years[y] + 1)
year_str = paste(years[y], "-", substr(next_year, nchar(next_year) -1, nchar(next_year)), sep="")
}
else { # otherwise, keep year as is.
year_str = as.character(years[y])
}
# Put together the pieces of the url
url = paste(BASE_URL, "/sports/", sport, "/roster/", year_str, sep="")
# Read the data.
tables = read_html(url) %>% html_table()
# Which element of the tables list the roster is on depends on the school.
roster = data.frame(tables[3])
# Some sports have men's and women's rosters combined in two different tables. This adds that extra table in.
if (sport %in% c("cross-country", "track-and-field")) {
roster = rbind(roster, data.frame(tables[4]))
}
# Adding a column for the year and the sport
roster$Year = rep(year, nrow(roster))
roster$Sport = rep(sport, nrow(roster))
# This checks if there is a column including the name "hometown". If there is one, it adds a Hometown column, using the hometown_split() function.
for (i in 1:length(colnames(roster))){
if (length(grep("[hH]ometown", colnames(roster)[i])) > 0){
roster$Hometown = hometown_split(roster[[colnames(roster)[i]]])
}
# If there is a column "Name", add it to the roster dataframe.
if (length(grep("[nN]ame", colnames(roster)[i])) > 0){
roster$Name = roster[[colnames(roster)[i]]]
}
}
# If we don't find a column with "Hometown" in it, likely this url doesn't contain any data. We move on to the next year/sport.
if (!("Hometown" %in% colnames(roster))) {
next
}
# Get the columns we want from the roster, and add them to the overall college dataframe.
roster = roster %>% select(Name, Hometown, Year, Sport)
college_df = rbind(college_df, roster)
}
# For monitoring purposes
# print(paste("Finished with ", sport))
}
# Typically, csv files are written for each school, so we can combine them in the cleaning. I will not do that here, but instead show a snapshot of the dataframe.
# write.csv(college_df, "MIZZOU.csv", row.names=F)
install.packages("caret")
View(all_schools)
all_schools$Sport
sport_names = all_schools$Sport
sport_names
sport_names = all_schools$Sport
for (sport in sport_names) {
print(sport)
}
sport_names = all_schools$Sport
unique(sport_names)
names = unique(sport_names)
name_replacements = c("baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "womens-rowing", "baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "xc-track", "xc-track", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "xc-track", "swimming-and-diving", "swimming-and-diving", "xc-track", "womens-lacrosse", "mens-basketball", "womens-basketball", "xc-track", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "mens-soccer", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "baseball", "softball", "mens-basketball", "xc-track", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "beach-volleyball", "wrestling", "xc-track", "xc-track", "swimming-and-diving", "xc-track", "womens-lacrosse")
length(name_replacements) == length(names)
names = unique(sport_names)
name_replacements = c("baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "womens-rowing", "baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "xc-track", "xc-track", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "xc-track", "swimming-and-diving", "swimming-and-diving", "xc-track", "womens-lacrosse", "mens-basketball", "womens-basketball", "xc-track", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "mens-soccer", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "baseball", "softball", "mens-basketball", "xc-track", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "beach-volleyball", "wrestling", "xc-track", "xc-track", "swimming-and-diving", "xc-track", "womens-lacrosse")
sport_name_changes = data.frame(Name = names, Modified = name_replacements)
View(sport_name_changes)
names = unique(sport_names)
name_replacements = c("baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "womens-rowing", "baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "xc-track", "xc-track", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "xc-track", "swimming-and-diving", "swimming-and-diving", "xc-track", "womens-lacrosse", "mens-basketball", "womens-basketball", "xc-track", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "mens-soccer", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "baseball", "softball", "mens-basketball", "xc-track", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "beach-volleyball", "wrestling", "xc-track", "xc-track", "swimming-and-diving", "xc-track", "womens-lacrosse")
sport_name_changes = data.frame(Name = names, Modified = name_replacements)
show_table(sport_name_changes)
sport_name_changes[sport_name_changes["Name"] == "w-swim"]
sport_name_changes[sport_name_changes["Name"] == "w-swim"]$Modified
sport_name_changes[sport_name_changes["Name"] == "w-swim"]
sport_name_changes[sport_name_changes["Name"] == "w-swim"][2]
# Apply this to the all_sports sport list
new_sports = c()
for (sport in all_sports$Sport){
new_sports = c(new_sports, sport_name_changes[sport_name_changes["Name"] == sport][2])
}
# Apply this to the all_sports sport list
new_sports = c()
for (sport in all_schools$Sport){
new_sports = c(new_sports, sport_name_changes[sport_name_changes["Name"] == sport][2])
}
all_schools$Sport = new_sports
View(all_schools)
# Apply this to the all_sports sport list
new_sports = c()
for (sport in all_schools$Sport){
new_sports = c(new_sports, sport_name_changes[sport_name_changes["Name"] == sport][2])
}
all_schools$Sport = new_sports
tibble(c(length(names), length(unique(new_sports)))
# Apply this to the all_sports sport list
new_sports = c()
for (sport in all_schools$Sport){
new_sports = c(new_sports, sport_name_changes[sport_name_changes["Name"] == sport][2])
}
all_schools$Sport = new_sports
print(paste("Old number of names:", length(names), "New number of names", length(unique(new_sports))))
# Apply this to the all_sports sport list
new_sports = c()
for (sport in all_schools$Sport){
new_sports = c(new_sports, sport_name_changes[sport_name_changes["Name"] == sport][2])
}
all_schools$Sport = new_sports
print(paste("Old number of names:", length(names), "New number of names", length(unique(new_sports))))
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
library(tidyverse)
library(rvest)
library(kableExtra)
show_table = function(df, caption="") {
return (df %>% kbl(caption = caption) %>% kable_classic_2(bootstrap_options = c("striped", "hover"), full_width = F, font_size=20, html_font="Cambria"))
}
show_table(head(read_csv("./Missouri/mizzou.csv")))
# Get all files from this directory
files = list.files(recursive=T)
# Get all .csv files, this will remove the .R scripts
csv_files = files[endsWith(files, ".csv")]
all_schools = data.frame()
for (f in csv_files) {
file = read_csv(f)
file$School = rep(str_split_1(f, "/")[1], nrow(file))
all_schools = rbind(all_schools, file)
}
show_table(head(all_schools))
show_table(tail(all_schools))
sport_names = all_schools$Sport
unique(sport_names)
names = unique(sport_names)
name_replacements = c("baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "womens-rowing", "baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "xc-track", "xc-track", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "xc-track", "swimming-and-diving", "swimming-and-diving", "xc-track", "womens-lacrosse", "mens-basketball", "womens-basketball", "xc-track", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "mens-soccer", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "baseball", "softball", "mens-basketball", "xc-track", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "beach-volleyball", "wrestling", "xc-track", "xc-track", "swimming-and-diving", "xc-track", "womens-lacrosse")
sport_name_changes = data.frame(Name = names, Modified = name_replacements)
show_table(tail(sport_name_changes))
# Apply this to the all_sports sport list
new_sports = c()
for (sport in all_schools$Sport){
new_sports = c(new_sports, sport_name_changes[sport_name_changes["Name"] == sport][2])
}
all_schools$Sport = new_sports
print(paste("Old number of names:", length(names), "New number of names", length(unique(new_sports))))
setwd("~/Personal/projects/current/uw-data-contest")
getwd()
setwd("Personal/projects/current/uw-data-contest")
setwd()
getwd()
list.files()
list.files()
list.files()
list.files()
list.dirs()
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
library(tidyverse)
library(rvest)
library(kableExtra)
library(leaflet)
library(leaflet.providers)
library(ggmap)
library(sqldf)
library(jsonlite)
library(geosphere)
library(ggrepel)
nil_diff_school = schools_dist_var %>%
mutate(nil = ifelse(Year >= 2021, "after", "before")) %>%
group_by(nil, School) %>%
summarize(avg_var = mean(distance_var)) %>%
pivot_wider(names_from=nil, values_from=avg_var) %>%
mutate(var_diff = after-before)
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
library(tidyverse)
library(rvest)
library(kableExtra)
library(leaflet)
library(leaflet.providers)
library(ggmap)
library(sqldf)
library(jsonlite)
library(geosphere)
library(ggrepel)
show_table = function(df, caption="") {
return (df %>% kbl(caption = caption) %>% kable_classic_2(bootstrap_options = c("striped", "hover"), full_width = F, font_size=20, html_font="Cambria"))
}
show_table(head(read_csv("./Missouri/mizzou.csv")))
# Get all files from this directory
files = list.files(recursive=T)
# Get all .csv files, this will remove the .R scripts
csv_files = files[endsWith(files, ".csv")]
csv_files = csv_files[!(csv_files %in% c("geocodes.csv", "rosters.csv"))]
all_schools = data.frame()
for (f in csv_files) {
file = read_csv(f)
file$School = rep(str_split_1(f, "/")[1], nrow(file))
all_schools = rbind(all_schools, file)
}
show_table(head(all_schools))
show_table(tail(all_schools))
sport_names = all_schools$Sport
unique(sport_names)
names = unique(sport_names)
name_replacements = c("baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "womens-rowing", "baseball", "softball", "mens-basketball", "womens-basketball", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "xc-track", "xc-track", "xc-track", "womens-tennis", "mens-tennis", "volleyball", "xc-track", "swimming-and-diving", "swimming-and-diving", "xc-track", "womens-lacrosse", "mens-basketball", "womens-basketball", "xc-track", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "mens-soccer", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "baseball", "softball", "mens-basketball", "xc-track", "football", "mens-golf", "womens-golf", "swimming-and-diving", "gymnastics", "womens-soccer", "xc-track", "mens-tennis", "womens-tennis", "volleyball", "beach-volleyball", "wrestling", "xc-track", "xc-track", "swimming-and-diving", "xc-track", "womens-lacrosse")
sport_name_changes = data.frame(Name = names, Modified = name_replacements)
show_table(tail(sport_name_changes))
# Apply this to the all_sports sport list
new_sports = c()
for (sport in all_schools$Sport){
new_sports = c(new_sports, sport_name_changes[sport_name_changes["Name"] == sport][2])
}
all_schools$Sport = new_sports
print(paste("Old number of names:", length(names), "New number of names", length(unique(new_sports))))
hometowns = data.frame(City = all_schools$Hometown)
states = c()
cities = c()
for (city in hometowns$City){
if (is.na(city)){
states = c(states, NA)
cities = c(cities, NA)
next
}
cities = c(cities, str_trim(str_split_1(city, ",")[1]))
states = c(states, str_trim(str_split_1(city, ",")[2]))
}
hometowns$Town = cities
hometowns$State = states
# State revisions
revised_states = c()
for (state in hometowns$State) {
if (length(grep("A[lL]", state)) > 0) {
revised_states = c(revised_states, "Alabama")
}
else if (length(grep("L[aA]", state)) > 0) {
revised_states = c(revised_states, "Louisiana")
}
else if (length(grep("F[lL]", state)) > 0) {
revised_states = c(revised_states, "Florida")
}
else if (length(grep("Tenn", state)) > 0) {
revised_states = c(revised_states, "Tennessee")
}
else if (length(grep("Miss.", state)) > 0) {
revised_states = c(revised_states, "Mississippi")
}
else if (length(grep("Missis", state)) > 0){
revised_states = c(revised_states, "Mississippi")
}
else if (length(grep("M[dD]", state)) > 0) {
revised_states = c(revised_states, "Maryland")
}
else if (length(grep("G[aA]", state)) > 0) {
revised_states = c(revised_states, "Georgia")
}
else if (length(grep("V[aA]", state)) > 0) {
revised_states = c(revised_states, "Virginia")
}
else if (length(grep("C[aA]", state)) > 0) {
revised_states = c(revised_states, "California")
}
else if (length(grep("Tex", state)) > 0) {
revised_states = c(revised_states, "Texas")
}
else if (length(grep("S.C", state)) > 0) {
revised_states = c(revised_states, "South Carolina")
}
else if (length(grep("N.C", state)) > 0) {
revised_states = c(revised_states, "North Carolina")
}
else if (length(grep("Ark", state)) > 0) {
revised_states = c(revised_states, "Arkansas")
}
else if (length(grep("M[oO]", state)) > 0) {
revised_states = c(revised_states, "Missouri")
}
else if (length(grep("Ariz", state)) > 0) {
revised_states = c(revised_states, "Arizona")
}
else if (length(grep("K[yY]", state)) > 0) {
revised_states = c(revised_states, "Kentucky")
}
else if (length(grep("Mass", state)) > 0) {
revised_states = c(revised_states, "Massachussets")
}
else if (length(grep("Minn", state)) > 0) {
revised_states = c(revised_states, "Minnesota")
}
else if (length(grep("Colo", state)) > 0) {
revised_states = c(revised_states, "Colorado")
}
else if (length(grep("P[aA]", state)) > 0) {
revised_states = c(revised_states, "Pennsylvania")
}
else if (length(grep("N.J", state)) > 0) {
revised_states = c(revised_states, "New Jersey")
}
else if (length(grep("Ind", state)) > 0) {
revised_states = c(revised_states, "Indiana")
}
else if (length(grep("Wis", state)) > 0) {
revised_states = c(revised_states, "Wisconsin")
}
else if (length(grep("N.D", state)) > 0) {
revised_states = c(revised_states, "North Dakota")
}
else if (length(grep("Mich", state)) > 0) {
revised_states = c(revised_states, "Michigan")
}
else if (length(grep("Neb", state)) > 0) {
revised_states = c(revised_states, "Nebraska")
}
else if (length(grep("N.Y", state)) > 0) {
revised_states = c(revised_states, "New York")
}
else if (length(grep("Ill", state)) > 0) {
revised_states = c(revised_states, "Illinois")
}
else if (length(grep("Wash", state)) > 0) {
revised_states = c(revised_states, "Washington")
}
else if (length(grep("Ore", state)) > 0) {
revised_states = c(revised_states, "Oregon")
}
else if (length(grep("Okla", state)) > 0) {
revised_states = c(revised_states, "Oklahoma")
}
else{
revised_states = c(revised_states, state)
}
}
hometowns$State = revised_states
hometowns$City = paste(hometowns$Town, ", ", hometowns$State, sep="")
all_schools$Hometown = hometowns$City
# Write this to a csv to use for geocoding
write.csv(all_schools, "rosters.csv", row.names=F)
geocodes = read_csv("geocodes.csv")
show_table(head(geocodes))
schools = all_schools %>% select(Hometown, School) %>% group_by(Hometown, School) %>% summarize(n = length(Hometown)) %>% drop_na()
cities = sqldf("SELECT Hometown, School, max(n) as Num_Players FROM schools GROUP BY Hometown")
top_schools = c()
ns = c()
for (city in geocodes$Hometown) {
df = cities[cities["Hometown"] == city,] %>% select(School, Num_Players)
top_schools = append(top_schools, df$School[1])
ns = append(ns, df$Num_Players[1])
}
geocodes$School = top_schools
geocodes$Num_Players = ns
# These are some mapping functions that will allow us to see not only some statistics on the cities, but color them so we know what schools are getting the most recruits from each city.
school_color = function (school) {
school = school[1]
if (is.na(school)){
return ("black")
}
if (school == "Alabama") {
return ("#9E1B32")
}
if (school == "Auburn"){
return ("#E87722")
}
if (school == "Missouri"){
return ("#F1B82D")
}
if (school == "Arkansas"){
return ("#9D2235")
}
if (school == "Kentucky") {
return ("#0033A0")
}
if (school == "Florida") {
return ("#0021A5")
}
if (school == "Mississippi State") {
return ("#5D1725")
}
if (school == "LSU") {
return ("#461D7C")
}
if (school == "South Carolina") {
return ("#73000A")
}
if (school == "Vanderbilt") {
return ("#866D4B")
}
}
colors = c()
for (school in geocodes$School){
colors = c(colors, school_color(school))
}
geocodes$Color = colors
m = leaflet() %>%
addProviderTiles(provider=providers$Esri.WorldGrayCanvas) %>%
addCircleMarkers(geocodes$lon, geocodes$lat, label=geocodes$Hometown, popup=paste("<b>", geocodes$Hometown, "</b><br>", geocodes$Num_Players, "were recruited to", geocodes$School), radius=4.5, color=geocodes$Color, fillOpacity=1.0, stroke=F)
m
readRenviron("./.Renviron")
api_key = Sys.getenv("CENSUSKEY")
url = str_glue("https://api.census.gov/data/2019/acs/acs5?get=NAME,B01002_001E,B02001_002E,B02001_003E,B25010_001E,B01003_001E&for=place:*&in=state:*&key={api_key}")
data = fromJSON(url)
census_data = data.frame(data) %>% slice(2:nrow(data))
colnames(census_data) = c("City", "Avg_Age", "B02001_002E", "B02001_003E", "Avg_Household_Size", "Total_Pop", "state", "place")
census_data$B02001_002E = as.numeric(census_data$B02001_002E)
census_data$B02001_003E = as.numeric(census_data$B02001_003E)
census_data$Total_Pop = as.numeric(census_data$Total_Pop)
census_data = census_data %>%
mutate(Percent_White = (B02001_002E/Total_Pop) * 100) %>%
mutate(Percent_Black = (B02001_003E/Total_Pop) * 100) %>%
select(City, Avg_Age, Percent_White, Percent_Black, Avg_Household_Size)
data = fromJSON(url)
# Split City and State
split_city = function(name){
split_list = strsplit(name, ",")[[1]]
city_name = split_list[1]
city_split = strsplit(city_name, " ")[[1]]
city_name = paste(city_split[-length(city_split)], collapse = " ")
return (city_name)
}
get_state = function(name) {
split_list = strsplit(name, ",")[[1]]
state = str_trim(split_list[2])
return(state)
}
census_data$State = lapply(census_data$City, get_state)
census_data$City = lapply(census_data$City, split_city)
census_data$City_str = paste(census_data$City, ", ", census_data$State, sep="")
cities_w_census = census_data %>%
filter(City_str %in% cities$Hometown)
# What cities in our database have the highest percentage of black players?
pct_black = cities_w_census %>%
select(City_str, Percent_Black) %>%
arrange(desc(Percent_Black)) %>%
top_n(25)
ggplot(pct_black, aes(y=reorder(City_str, Percent_Black), x=Percent_Black)) +
geom_col(fill="lightblue", color="black") +
ylab("City Name") +
xlab("% of Black People") +
ggtitle("% of Black Population by Census City")
register_google(Sys.getenv("MAPSAPIKEY"))
geocoded_top_50 = cities_w_census %>%
select(City_str, Percent_Black) %>%
arrange(desc(Percent_Black)) %>%
top_n(50) %>%
mutate_geocode(City_str)
m %>% addCircleMarkers(geocoded_top_50$lon, geocoded_top_50$lat, label=geocoded_top_50$City_str, popup=paste("<b>", geocoded_top_50$City_str, "</b><br>", round(geocoded_top_50$Percent_Black, 2), "% Black"), color="purple")
universities = unique(schools$School)
uni_cities = c("Nashville, TN", "Lexington, KY", "Tuscaloosa, AL", "Gainesville, FL", "Baton Rouge, LA", "Starkville, MS", "Columbia, SC", "Fayetteville, AR", "Auburn, AL", "Columbia, MO")
school_locs = data.frame(School = universities, City = uni_cities) %>% mutate_geocode(City)
lons = c()
lats = c()
# Apply to all players dataframe
for (city in all_schools$Hometown) {
geocode = geocodes[geocodes$Hometown == city,]
lons = c(lons, geocode$lon)
lats = c(lats, geocode$lat)
}
all_schools$lon = lons
all_schools$lat = lats
sc_lons = c()
sc_lats = c()
for (school in all_schools$School) {
code = school_locs[school_locs$School == school,]
sc_lons = c(sc_lons, code$lon)
sc_lats = c(sc_lats, code$lat)
}
all_schools$school_lon = sc_lons
all_schools$school_lat = sc_lats
dists = c()
for (i in 1:nrow(all_schools)) {
dists = c(dists, distHaversine(c(all_schools$lon[i], all_schools$lat[i]), c(all_schools$school_lon[i], all_schools$school_lat[i]))/1000)
}
all_schools$school_dist = dists
schools_dist_var = all_schools %>%
drop_na() %>%
group_by(School, Year) %>%
summarize(distance_var = var(school_dist)) %>%
mutate(Color = school_color(School), label= toupper(substr(School, 1, 3)))
group.colors = c("Alabama" = "#9E1B32", "Arkansas" = "#9D2235", "Auburn" = "#E87722", "Florida" = "#0021A5", "Kentucky" = "#0033A0", "LSU" = "#461D7C", "Mississippi State" = "#5D1725", "Missouri" = "#F1B82D", "South Carolina" = "#73000A", "Vanderbilt" = "#866D4B")
ends = schools_dist_var %>% filter(Year == 2023)
ggplot(schools_dist_var, aes(x=Year, y=distance_var)) +
geom_smooth(aes(color=School), ,se=F, size=1.25) +
scale_color_manual(values=group.colors) +
scale_x_continuous(breaks=c(2013, 2015, 2017, 2019, 2021, 2023)) +
geom_text_repel(aes(label=label), data=ends, nudge_x=1, na.rm=T) +
ggtitle("Variance in Distance from 2013-2023") +
ylab("Variance in Distance") +
theme(axis.text.y=element_blank(), axis.ticks.y = element_blank())
nil_difference = schools_dist_var %>%
mutate(nil = ifelse(Year >= 2021, "2021-2023", "2013-2020")) %>%
group_by(nil) %>%
summarize(avg_var = mean(distance_var))
ggplot(nil_difference, aes(x=nil, y=avg_var)) +
geom_col(width=0.5, color="black", fill="lightblue") +
theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) +
ylab("Average Variance") +
xlab("Year Range") +
ggtitle("Average Variance in Distance Before and After NIL Introduction")
nil_diff_school = schools_dist_var %>%
mutate(nil = ifelse(Year >= 2021, "after", "before")) %>%
group_by(nil, School) %>%
summarize(avg_var = mean(distance_var)) %>%
pivot_wider(names_from=nil, values_from=avg_var) %>%
mutate(var_diff = after-before)
ggplot(nil_diff_school, aes(x=School, y=var_diff, fill=School)) +
geom_col(width=0.5, color="black") +
theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.text.x = element_text(angle=90, vjust=1)) +
scale_fill_manual(values=group.colors) +
ylab("Difference in Variance") +
xlab("Year Range") +
ggtitle("Difference in Variance Before and After NIL Introduction")
